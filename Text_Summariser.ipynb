{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ageraustine/text-summariser/blob/master/Text_Summariser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8avr_DQlIwv9"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install keras_nlp\n",
        "!pip install datasets\n",
        "!pip install rouge-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "cddf3e841f5f45dbab55719594381676",
            "6b05663a89014e29bd42d8ece73218e9",
            "8ca21da8401c4ab58213295c219b7624",
            "95efbf0aba9e489db2c8ac4b46e59bb8",
            "a4899ab478ec4eeba806a12181a8a12e",
            "d7f7cee3a25b4718897c391d3994e155",
            "ab89a11a1bea475db0f1f399a705be71",
            "9d4ea528e8774ed2b6ed48d99adc7fd7",
            "b97fa5789073424c93e597a580fb2faa",
            "ee2667ea26a04f4e9ec7617a9732bd13",
            "2c8018547b9e4bbc892945ced455aca6"
          ]
        },
        "id": "NxgY7aEHc1Um",
        "outputId": "def5a4cd-434e-400f-d4de-0062ce10648d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving 0 files to the new cache system\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cddf3e841f5f45dbab55719594381676"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "import math\n",
        "import transformers\n",
        "import keras_nlp\n",
        "import rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdxugK7sgDjf",
        "outputId": "989490c9-a7c6-44a2-ecfe-7bd726b27696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwaVrgF721u3"
      },
      "source": [
        "                              Unzip The Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DwNzDZyF1nxR"
      },
      "outputs": [],
      "source": [
        "dataset_dir = os.getcwd() + '/dataset'\n",
        "zipcsv_dir = '/content/drive/MyDrive/ml/nlp/datasets/wikihowAll.zip'\n",
        "\n",
        "if not os.path.exists(\"/content/dataset/wikihowAll.csv\"):\n",
        "  with zipfile.ZipFile(zipcsv_dir, \"r\") as zp:\n",
        "    zp.extractall(dataset_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwb12gmw2-6R"
      },
      "source": [
        "                                     Load The Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3ZJbF0Hg3Blj"
      },
      "outputs": [],
      "source": [
        "# The percentage of the dataset you want to split as train and test\n",
        "TRAIN_TEST_SPLIT = 0.1\n",
        "\n",
        "MAX_INPUT_LENGTH = 1024  # Maximum length of the input to the model\n",
        "MIN_TARGET_LENGTH = 5  # Minimum length of the output by the model\n",
        "MAX_TARGET_LENGTH = 128  # Maximum length of the output by the model\n",
        "BATCH_SIZE = 8  # Batch-size for training our model\n",
        "LEARNING_RATE = 2e-5  # Learning-rate for training our model\n",
        "MAX_EPOCHS = 1  # Maximum number of epochs we will train the model for\n",
        "MODEL_CHECKPOINT = \"t5-small\"\n",
        "\n",
        "csv_path = dataset_dir + '/wikihowAll.csv'\n",
        "dataset_df = pd.read_csv(csv_path, nrows=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "m700BkhAeUeH"
      },
      "outputs": [],
      "source": [
        "filtered_df = dataset_df[['headline', 'text']].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Axsr8djr4wkY"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        " \n",
        "raw_dataset = Dataset.from_pandas(filtered_df)\n",
        "\n",
        "raw_dataset = raw_dataset.train_test_split(\n",
        "    train_size=TRAIN_TEST_SPLIT, test_size=TRAIN_TEST_SPLIT\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtwnSvr1CICk"
      },
      "source": [
        "                                   Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVKygR4ZDILt"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "MODEL_CHECKPOINT = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5f2n6sgg2j8_"
      },
      "outputs": [],
      "source": [
        "if MODEL_CHECKPOINT in [\"t5-small\", \"t5-base\", \"t5-large\", \"t5-3b\", \"t5-11b\"]:\n",
        "    prefix = \"summarize: \"\n",
        "else:\n",
        "    prefix = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "s4ua1Bsv25qt"
      },
      "outputs": [],
      "source": [
        "def tokenize_data(data):\n",
        "    inputs = [prefix + doc for doc in data['text']]\n",
        "    model_inputs = tokenizer(inputs, max_length=MAX_INPUT_LENGTH, truncation=True)\n",
        "\n",
        "    # Setup the tokenizer for targets\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            data['headline'], max_length=MAX_TARGET_LENGTH, truncation=True\n",
        "        )\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6_elTgZrrR0"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets = raw_dataset.map(tokenize_data, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZAK4I07_Ldz"
      },
      "source": [
        "                              Defining the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MEXvkhw8nHm",
        "outputId": "58be904a-6a1f-4613-b016-d98724876504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFAutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
        "\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(MODEL_CHECKPOINT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "EKC7GU94_TKb"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGplTeuL_se6",
        "outputId": "0cebf091-4610-4138-818c-7ec4aee03bee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        }
      ],
      "source": [
        "train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "test_dataset = tokenized_datasets[\"test\"].to_tf_dataset(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
        "    shuffle=False,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "generation_dataset = (\n",
        "    tokenized_datasets[\"test\"]\n",
        "    .shuffle()\n",
        "    .select(list(range(200)))\n",
        "    .to_tf_dataset(\n",
        "        batch_size=BATCH_SIZE,\n",
        "        columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
        "        shuffle=False,\n",
        "        collate_fn=data_collator,\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYNDI-z12Fux"
      },
      "source": [
        "                            Building and Compiling The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHhB4qEC2JC_",
        "outputId": "970d4e40-1250-41b4-fb37-cf7c3ca2b6be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        }
      ],
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "model.compile(optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJLyBPE82Tra"
      },
      "source": [
        "                                    Training and EValuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "09205pCX2RgI"
      },
      "outputs": [],
      "source": [
        "import keras_nlp\n",
        "import rouge_score\n",
        "\n",
        "rouge_l = keras_nlp.metrics.RougeL()\n",
        "\n",
        "def metric_fn(eval_predictions):\n",
        "    predictions, labels = eval_predictions\n",
        "    decoded_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    for label in labels:\n",
        "        label[label < 0] = tokenizer.pad_token_id  # Replace masked label tokens\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    result = rouge_l(decoded_labels, decoded_predictions)\n",
        "    # We will print only the F1 score, you can use other aggregation metrics as well\n",
        "    result = {\"RougeL\": result[\"f1_score\"]}\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnpicwYaF8Fg",
        "outputId": "211c1bc4-afc1-4359-c37a-6e4c5adff6d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No label_cols specified for KerasMetricCallback, assuming you want the 'labels' key.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 30/125 [======>.......................] - ETA: 1:16:11 - loss: 3.8462"
          ]
        }
      ],
      "source": [
        "from transformers.keras_callbacks import KerasMetricCallback\n",
        "\n",
        "metric_callback = KerasMetricCallback(\n",
        "    metric_fn, eval_dataset=generation_dataset, predict_with_generate=True\n",
        ")\n",
        "\n",
        "callbacks = [metric_callback]\n",
        "\n",
        "# For now we will use our test set as our validation_data\n",
        "model.fit(\n",
        "    train_dataset, validation_data=test_dataset, epochs=MAX_EPOCHS, callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8RiPvORGXNu"
      },
      "source": [
        "Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIodaSUkGZVI"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer, framework=\"tf\")\n",
        "\n",
        "summarizer(\n",
        "    raw_dataset[\"test\"][0][\"text\"],\n",
        "    min_length=MIN_TARGET_LENGTH,\n",
        "    max_length=MAX_TARGET_LENGTH,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyNE+QYP6qcw2vzWlQ1cxsBk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cddf3e841f5f45dbab55719594381676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b05663a89014e29bd42d8ece73218e9",
              "IPY_MODEL_8ca21da8401c4ab58213295c219b7624",
              "IPY_MODEL_95efbf0aba9e489db2c8ac4b46e59bb8"
            ],
            "layout": "IPY_MODEL_a4899ab478ec4eeba806a12181a8a12e"
          }
        },
        "6b05663a89014e29bd42d8ece73218e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7f7cee3a25b4718897c391d3994e155",
            "placeholder": "​",
            "style": "IPY_MODEL_ab89a11a1bea475db0f1f399a705be71",
            "value": ""
          }
        },
        "8ca21da8401c4ab58213295c219b7624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d4ea528e8774ed2b6ed48d99adc7fd7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b97fa5789073424c93e597a580fb2faa",
            "value": 0
          }
        },
        "95efbf0aba9e489db2c8ac4b46e59bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee2667ea26a04f4e9ec7617a9732bd13",
            "placeholder": "​",
            "style": "IPY_MODEL_2c8018547b9e4bbc892945ced455aca6",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "a4899ab478ec4eeba806a12181a8a12e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7f7cee3a25b4718897c391d3994e155": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab89a11a1bea475db0f1f399a705be71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d4ea528e8774ed2b6ed48d99adc7fd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b97fa5789073424c93e597a580fb2faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee2667ea26a04f4e9ec7617a9732bd13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c8018547b9e4bbc892945ced455aca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}