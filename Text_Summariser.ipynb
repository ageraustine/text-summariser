{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ageraustine/text-summariser/blob/master/Text_Summariser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8avr_DQlIwv9"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install keras_nlp\n",
        "!pip install datasets\n",
        "!pip install rouge-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxgY7aEHc1Um"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "import math\n",
        "import transformers\n",
        "import keras_nlp\n",
        "import rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdxugK7sgDjf"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwaVrgF721u3"
      },
      "source": [
        "                              Unzip The Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DwNzDZyF1nxR"
      },
      "outputs": [],
      "source": [
        "dataset_dir = os.getcwd() + '/dataset'\n",
        "zipcsv_dir = '/content/drive/MyDrive/ml/nlp/datasets/wikihowAll.zip'\n",
        "\n",
        "if not os.path.exists(\"/content/dataset/wikihowAll.csv\"):\n",
        "  with zipfile.ZipFile(zipcsv_dir, \"r\") as zp:\n",
        "    zp.extractall(dataset_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwb12gmw2-6R"
      },
      "source": [
        "                                     Load The Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3ZJbF0Hg3Blj"
      },
      "outputs": [],
      "source": [
        "# The percentage of the dataset you want to split as train and test\n",
        "TRAIN_TEST_SPLIT = 0.1\n",
        "\n",
        "MAX_INPUT_LENGTH = 1024  # Maximum length of the input to the model\n",
        "MIN_TARGET_LENGTH = 5  # Minimum length of the output by the model\n",
        "MAX_TARGET_LENGTH = 128  # Maximum length of the output by the model\n",
        "BATCH_SIZE = 8  # Batch-size for training our model\n",
        "LEARNING_RATE = 2e-5  # Learning-rate for training our model\n",
        "MAX_EPOCHS = 1  # Maximum number of epochs we will train the model for\n",
        "MODEL_CHECKPOINT = \"t5-small\"\n",
        "\n",
        "csv_path = dataset_dir + '/wikihowAll.csv'\n",
        "dataset_df = pd.read_csv(csv_path, nrows=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "m700BkhAeUeH"
      },
      "outputs": [],
      "source": [
        "filtered_df = dataset_df[['headline', 'text']].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Axsr8djr4wkY"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        " \n",
        "raw_dataset = Dataset.from_pandas(filtered_df)\n",
        "\n",
        "raw_dataset = raw_dataset.train_test_split(\n",
        "    train_size=TRAIN_TEST_SPLIT, test_size=TRAIN_TEST_SPLIT\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtwnSvr1CICk"
      },
      "source": [
        "                                   Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVKygR4ZDILt"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "MODEL_CHECKPOINT = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5f2n6sgg2j8_"
      },
      "outputs": [],
      "source": [
        "if MODEL_CHECKPOINT in [\"t5-small\", \"t5-base\", \"t5-large\", \"t5-3b\", \"t5-11b\"]:\n",
        "    prefix = \"summarize: \"\n",
        "else:\n",
        "    prefix = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "s4ua1Bsv25qt"
      },
      "outputs": [],
      "source": [
        "def tokenize_data(data):\n",
        "    inputs = [prefix + doc for doc in data['text']]\n",
        "    model_inputs = tokenizer(inputs, max_length=MAX_INPUT_LENGTH, truncation=True)\n",
        "\n",
        "    # Setup the tokenizer for targets\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            data['headline'], max_length=MAX_TARGET_LENGTH, truncation=True\n",
        "        )\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6_elTgZrrR0"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets = raw_dataset.map(tokenize_data, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZAK4I07_Ldz"
      },
      "source": [
        "                              Defining the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MEXvkhw8nHm"
      },
      "outputs": [],
      "source": [
        "from transformers import TFAutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
        "\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(MODEL_CHECKPOINT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "EKC7GU94_TKb"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGplTeuL_se6"
      },
      "outputs": [],
      "source": [
        "train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "test_dataset = tokenized_datasets[\"test\"].to_tf_dataset(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
        "    shuffle=False,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "generation_dataset = (\n",
        "    tokenized_datasets[\"test\"]\n",
        "    .shuffle()\n",
        "    .select(list(range(200)))\n",
        "    .to_tf_dataset(\n",
        "        batch_size=BATCH_SIZE,\n",
        "        columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
        "        shuffle=False,\n",
        "        collate_fn=data_collator,\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYNDI-z12Fux"
      },
      "source": [
        "                            Building and Compiling The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHhB4qEC2JC_"
      },
      "outputs": [],
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "model.compile(optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJLyBPE82Tra"
      },
      "source": [
        "                                    Training and EValuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "09205pCX2RgI"
      },
      "outputs": [],
      "source": [
        "import keras_nlp\n",
        "import rouge_score\n",
        "\n",
        "rouge_l = keras_nlp.metrics.RougeL()\n",
        "\n",
        "def metric_fn(eval_predictions):\n",
        "    predictions, labels = eval_predictions\n",
        "    decoded_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    for label in labels:\n",
        "        label[label < 0] = tokenizer.pad_token_id  # Replace masked label tokens\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    result = rouge_l(decoded_labels, decoded_predictions)\n",
        "    # We will print only the F1 score, you can use other aggregation metrics as well\n",
        "    result = {\"RougeL\": result[\"f1_score\"]}\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnpicwYaF8Fg",
        "outputId": "211c1bc4-afc1-4359-c37a-6e4c5adff6d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No label_cols specified for KerasMetricCallback, assuming you want the 'labels' key.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 36/125 [=======>......................] - ETA: 1:11:00 - loss: 3.7532"
          ]
        }
      ],
      "source": [
        "from transformers.keras_callbacks import KerasMetricCallback\n",
        "\n",
        "metric_callback = KerasMetricCallback(\n",
        "    metric_fn, eval_dataset=generation_dataset, predict_with_generate=True\n",
        ")\n",
        "\n",
        "callbacks = [metric_callback]\n",
        "\n",
        "# For now we will use our test set as our validation_data\n",
        "model.fit(\n",
        "    train_dataset, validation_data=test_dataset, epochs=MAX_EPOCHS, callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8RiPvORGXNu"
      },
      "source": [
        "Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIodaSUkGZVI"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer, framework=\"tf\")\n",
        "\n",
        "summarizer(\n",
        "    raw_dataset[\"test\"][0][\"text\"],\n",
        "    min_length=MIN_TARGET_LENGTH,\n",
        "    max_length=MAX_TARGET_LENGTH,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyNE+QYP6qcw2vzWlQ1cxsBk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}